{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be138f6f",
   "metadata": {
    "id": "be138f6f",
    "papermill": {
     "duration": 0.02181,
     "end_time": "2024-12-18T17:13:30.324107",
     "exception": false,
     "start_time": "2024-12-18T17:13:30.302297",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Knowledge Distillation using Contrastive Learning (CLIP)\n",
    "\n",
    "In this notebook, we explore **Knowledge Distillation** from a large monolingual model into a smaller multilingual model using **Contrastive Learning**, specifically leveraging the **CLIP** (Contrastive Language-Image Pretraining) loss.\n",
    "\n",
    "We employ a small paired **English-Persian** dataset to define the loss pairs for training. This demonstrates the mechanics of using CLIP loss for aligning embedding spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dba4d2",
   "metadata": {
    "id": "a1dba4d2",
    "papermill": {
     "duration": 0.014965,
     "end_time": "2024-12-18T17:13:30.385132",
     "exception": false,
     "start_time": "2024-12-18T17:13:30.370167",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Overview\n",
    "\n",
    "**CLIP** bridges the gap between modalities (or languages in this case) by aligning corresponding embeddings in a shared space. It uses a **contrastive loss** to ensure that:\n",
    "- **Positive pairs** (e.g., an English sentence and its Persian translation) have high similarity.\n",
    "- **Negative pairs** (unmatched samples) have low similarity.\n",
    "\n",
    "**Knowledge Distillation** transfers knowledge from a large \"teacher\" model to a smaller \"student\" model. Here:\n",
    "- **Teacher:** `EVA02-E-14-plus` (Large, Pretrained).\n",
    "- **Student:** `setu4993/smaller-LaBSE` (Small, Multilingual).\n",
    "\n",
    "### Challenges\n",
    "CLIP typically requires massive batch sizes (>19k) to provide sufficient negative samples. Due to resource constraints (Colab/Local GPU), we use a smaller batch size to demonstrate the *procedure* and training dynamics, rather than achieving state-of-the-art performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7da461e",
   "metadata": {
    "id": "e7da461e",
    "papermill": {
     "duration": 0.014905,
     "end_time": "2024-12-18T17:13:30.474341",
     "exception": false,
     "start_time": "2024-12-18T17:13:30.459436",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69339c7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-20T09:34:20.763257Z",
     "iopub.status.busy": "2025-01-20T09:34:20.762951Z",
     "iopub.status.idle": "2025-01-20T09:34:33.158618Z",
     "shell.execute_reply": "2025-01-20T09:34:33.157650Z",
     "shell.execute_reply.started": "2025-01-20T09:34:20.763229Z"
    },
    "id": "69339c7a",
    "outputId": "dce65f1d-d82f-4a7b-f7db-ee2abf6b2149",
    "papermill": {
     "duration": 20.264414,
     "end_time": "2024-12-18T17:13:50.783672",
     "exception": false,
     "start_time": "2024-12-18T17:13:30.519258",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1MVx_gIkX4tQ8ya2OsHt0mqLmw1Pf2CcK\n",
      "To: /kaggle/working/train.csv\n",
      "100%|███████████████████████████████████████| 7.35M/7.35M [00:00<00:00, 151MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Co-dwJfWw-C_ral0hoAS_X94wN-_vbCj\n",
      "To: /kaggle/working/val.csv\n",
      "100%|███████████████████████████████████████| 2.45M/2.45M [00:00<00:00, 198MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Install necessary data files\n",
    "# !gdown \"https://drive.google.com/uc?id=1MVx_gIkX4tQ8ya2OsHt0mqLmw1Pf2CcK\" -O train.csv\n",
    "# !gdown \"https://drive.google.com/uc?id=1Co-dwJfWw-C_ral0hoAS_X94wN-_vbCj\" -O val.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d93c5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T17:13:50.816136Z",
     "iopub.status.busy": "2024-12-18T17:13:50.815755Z",
     "iopub.status.idle": "2024-12-18T17:14:15.313938Z",
     "shell.execute_reply": "2024-12-18T17:14:15.312837Z"
    },
    "id": "70d93c5e",
    "outputId": "86c15384-b19a-4f02-c99b-e098eb12bd49",
    "papermill": {
     "duration": 24.516699,
     "end_time": "2024-12-18T17:14:15.316512",
     "exception": false,
     "start_time": "2024-12-18T17:13:50.799813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (70.0.0)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/1824580759.py:4: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open_clip-torch is NOT installed\n",
      "Collecting open_clip-torch\n",
      "  Downloading open_clip_torch-2.29.0-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: torch>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from open_clip-torch) (2.4.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from open_clip-torch) (0.19.0)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from open_clip-torch) (2024.5.15)\n",
      "Collecting ftfy (from open_clip-torch)\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from open_clip-torch) (4.66.4)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from open_clip-torch) (0.26.2)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from open_clip-torch) (0.4.5)\n",
      "Requirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (from open_clip-torch) (1.0.11)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open_clip-torch) (3.15.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open_clip-torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open_clip-torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open_clip-torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open_clip-torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open_clip-torch) (2024.6.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from ftfy->open_clip-torch) (0.2.13)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open_clip-torch) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open_clip-torch) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open_clip-torch) (2.32.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->open_clip-torch) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->open_clip-torch) (10.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub->open_clip-torch) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.9.0->open_clip-torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open_clip-torch) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open_clip-torch) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open_clip-torch) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open_clip-torch) (2024.6.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.9.0->open_clip-torch) (1.3.0)\n",
      "Downloading open_clip_torch-2.29.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: ftfy, open_clip-torch\n",
      "Successfully installed ftfy-6.3.1 open_clip-torch-2.29.0\n",
      "open_clip-torch was successfully installed.\n",
      "pandas (2.2.3) is installed\n",
      "numpy (1.26.4) is installed\n",
      "matplotlib (3.7.5) is installed\n",
      "transformers (4.46.3) is installed\n",
      "tqdm (4.66.4) is installed\n",
      "torch (2.4.0) is installed\n",
      "datasets (3.1.0) is installed\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "import sys\n",
    "import subprocess\n",
    "import itertools\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModel\n",
    "import open_clip\n",
    "from open_clip import model as TE\n",
    "from tqdm import tqdm\n",
    "\n",
    "def install_package(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "REQUIRED_PACKAGES = [\n",
    "    'open_clip_torch',\n",
    "    'gdown',\n",
    "    'pandas',\n",
    "    'numpy',\n",
    "    'matplotlib',\n",
    "    'transformers',\n",
    "    'tqdm',\n",
    "    'torch',\n",
    "    'datasets',\n",
    "]\n",
    "\n",
    "# Uncomment to install packages if needed\n",
    "# for package in REQUIRED_PACKAGES:\n",
    "#     try:\n",
    "#         import pkg_resources\n",
    "#         pkg_resources.get_distribution(package)\n",
    "#     except Exception:\n",
    "#         install_package(package)\n",
    "\n",
    "print(\"Imports complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd519039",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T17:14:15.383716Z",
     "iopub.status.busy": "2024-12-18T17:14:15.383220Z",
     "iopub.status.idle": "2024-12-18T17:14:15.388059Z",
     "shell.execute_reply": "2024-12-18T17:14:15.387180Z"
    },
    "id": "fd519039",
    "papermill": {
     "duration": 0.024557,
     "end_time": "2024-12-18T17:14:15.389794",
     "exception": false,
     "start_time": "2024-12-18T17:14:15.365237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        print(\"Warning: CUDA not found, using CPU.\")\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a2eff9",
   "metadata": {
    "id": "67a2eff9",
    "papermill": {
     "duration": 0.016217,
     "end_time": "2024-12-18T17:14:15.422727",
     "exception": false,
     "start_time": "2024-12-18T17:14:15.406510",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Configuration\n",
    "Settings for the teacher model (OpenCLIP) and student model (LaBSE), along with training hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802d832e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T17:14:15.503624Z",
     "iopub.status.busy": "2024-12-18T17:14:15.503324Z",
     "iopub.status.idle": "2024-12-18T17:14:15.590038Z",
     "shell.execute_reply": "2024-12-18T17:14:15.589056Z"
    },
    "id": "802d832e",
    "papermill": {
     "duration": 0.11541,
     "end_time": "2024-12-18T17:14:15.591685",
     "exception": false,
     "start_time": "2024-12-18T17:14:15.476275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "configs = {\n",
    "    \"device\": device,\n",
    "    \"reference_checkPoint\" : \"EVA02-E-14-plus\",                # Teacher: OpenCLIP model\n",
    "    \"candidate_checkpoint\" : \"setu4993/smaller-LaBSE\",         # Student: Multilingual BERT-like model\n",
    "    \"train_path\" : \"train.csv\",\n",
    "    \"val_path\" : \"val.csv\",\n",
    "    \"save_path\" : \"./best-model.pth\",\n",
    "    \"english\" : \"en\",\n",
    "    \"persian\" : \"fa\",\n",
    "    \"batch_size\": 128,          \n",
    "    \"lr\": 1e-4,\n",
    "    \"epochs\": 3,\n",
    "    \"tok_percentile\" : 99,\n",
    "    \"temperature\": 0.07,\n",
    "    \"dropout\": 0.05,\n",
    "    \"unfreezed_layers\" : 10,   # Fine-tune only the top layers\n",
    "    \"weight_decay\": 1e-5,\n",
    "    \"patience\": 1,\n",
    "    \"factor\" : 0.8,\n",
    "    # Teacher Model Specs (EVA02-E-14-plus)\n",
    "    \"reference_embedding\": 1024,\n",
    "    \"reference_context_length\" : 77,\n",
    "    \"reference_vocab_size\" : 49408,\n",
    "    \"reference_heads\" : 20,\n",
    "    \"reference_width\" : 1280,\n",
    "    \"reference_layers\" : 32,\n",
    "    \"cls_token_index\" : 0,\n",
    "    \"project_to\" : 1024,       # Projection dimension for alignment\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b95e360",
   "metadata": {
    "id": "7b95e360",
    "papermill": {
     "duration": 0.015595,
     "end_time": "2024-12-18T17:14:15.623791",
     "exception": false,
     "start_time": "2024-12-18T17:14:15.608196",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Key Concepts\n",
    "\n",
    "**1. Temperature in Contrastive Learning**\n",
    "Temperature ($\\tau$) scales the logits in the softmax function.\n",
    "- **Low $\\tau$:** Sharpens the distribution, making the model more confident about the positive pair and penalizing negatives more harshly.\n",
    "- **High $\\tau$:** Smooths the distribution.\n",
    "We use a small temperature (e.g., 0.07) to encourage the model to be discriminative.\n",
    "\n",
    "**2. Freezing Layers**\n",
    "We freeze the majority of the pre-trained student model and only fine-tune the top layers (`unfreezed_layers: 10`) and the projection head. This:\n",
    "- Preserves the robust language understanding acquired during pre-training.\n",
    "- Reduces computational cost and prevents overfitting on our smaller dataset.\n",
    "\n",
    "**3. Token Percentile**\n",
    "`tok_percentile` determines the sequence length that covers, for example, 99% of the dataset. We truncate/pad to this length instead of the absolute maximum to optimize memory usage without losing significant information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9cfd8b",
   "metadata": {
    "id": "6a9cfd8b",
    "papermill": {
     "duration": 0.015679,
     "end_time": "2024-12-18T17:14:15.655199",
     "exception": false,
     "start_time": "2024-12-18T17:14:15.639520",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Preprocessing\n",
    "Functions to load CSVs, normalize text (Persian/English), and create DataLoaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d84bc5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T17:14:15.689321Z",
     "iopub.status.busy": "2024-12-18T17:14:15.688449Z",
     "iopub.status.idle": "2024-12-18T17:14:15.700724Z",
     "shell.execute_reply": "2024-12-18T17:14:15.699987Z"
    },
    "id": "5d84bc5a",
    "papermill": {
     "duration": 0.031369,
     "end_time": "2024-12-18T17:14:15.702439",
     "exception": false,
     "start_time": "2024-12-18T17:14:15.671070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_datasets_csv(prev_en_col, prev_fa_col, new_en_col, new_fa_col, train_path, val_path):\n",
    "    # Check if files exist\n",
    "    try:\n",
    "        df = pd.read_csv(train_path)\n",
    "        df_val = pd.read_csv(val_path)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Dataset files not found. Please ensure train.csv and val.csv are present.\")\n",
    "        # Create dummy data for demonstration if files are missing\n",
    "        df = pd.DataFrame({prev_en_col: [\"Hello\", \"World\"], prev_fa_col: [\"سلام\", \"جهان\"]})\n",
    "        df_val = pd.DataFrame({prev_en_col: [\"Test\", \"Data\"], prev_fa_col: [\"تست\", \"داده\"]})\n",
    "\n",
    "    if df.empty or df_val.empty:\n",
    "        raise ValueError(\"Dataset is empty\")\n",
    "\n",
    "    df_train = df.loc[:, [prev_en_col, prev_fa_col]].rename(columns={prev_en_col: new_en_col, prev_fa_col: new_fa_col})\n",
    "    df_val = df_val.loc[:, [prev_en_col, prev_fa_col]].rename(columns={prev_en_col: new_en_col, prev_fa_col: new_fa_col})\n",
    "\n",
    "    dataset_train = Dataset.from_pandas(df_train)\n",
    "    dataset_val = Dataset.from_pandas(df_val)\n",
    "\n",
    "    return dataset_train, dataset_val\n",
    "\n",
    "def get_ds_by_lang(persian_col, english_col):\n",
    "    def get_persian_ds(dataset):\n",
    "        return dataset[persian_col]\n",
    "\n",
    "    def get_english_ds(dataset):\n",
    "        return dataset[english_col]\n",
    "\n",
    "    return get_persian_ds, get_english_ds\n",
    "\n",
    "class TextNormalizer():\n",
    "    def __init__(self):\n",
    "        # Persian normalization table\n",
    "        translation_src = ' ىكي“”0123456789%إأآئيؤةك'\n",
    "        translation_dst = ' یکی\"\"۰۱۲۳۴۵۶۷۸۹٪اااییوهک'\n",
    "        self.translations = str.maketrans(translation_src, translation_dst)\n",
    "\n",
    "        patterns = [\n",
    "            (r' {2,}', ' '),       # extra spaces\n",
    "            (r'\\n+', ' '),         # newlines\n",
    "            (r'\\u200c+', ' '),     # ZWNJs\n",
    "            (r'[ـ\\r]', '')         # keshide, carriage returns\n",
    "        ]\n",
    "        self.character_refinement_patterns = [(re.compile(p), r) for p, r in patterns]\n",
    "\n",
    "    def normalize_fa(self, text):\n",
    "        text = text.lower().translate(self.translations)\n",
    "        text = re.sub('[^a-zA-Z۰-۹آ-ی ]', ' ', text)\n",
    "        for pattern, repl in self.character_refinement_patterns:\n",
    "            text = pattern.sub(repl, text)\n",
    "        return text.strip()\n",
    "\n",
    "    def normalize_en(self, text):\n",
    "        text = text.lower()\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        return text.strip()\n",
    "\n",
    "def apply_preprocess(datasets, configs=configs):\n",
    "    normalizer = TextNormalizer()\n",
    "    \n",
    "    def apply_row_normalization(example):\n",
    "        example[configs['persian']] = normalizer.normalize_fa(example[configs['persian']])\n",
    "        example[configs['english']] = normalizer.normalize_en(example[configs['english']])\n",
    "        return example\n",
    "\n",
    "    new_datasets = []\n",
    "    for dataset in datasets:\n",
    "        new_datasets.append(dataset.map(apply_row_normalization))\n",
    "\n",
    "    return new_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86190e87",
   "metadata": {
    "id": "86190e87",
    "papermill": {
     "duration": 0.016557,
     "end_time": "2024-12-18T17:14:15.735930",
     "exception": false,
     "start_time": "2024-12-18T17:14:15.719373",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utilities\n",
    "Helper functions for token handling and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0c992a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T17:14:15.771618Z",
     "iopub.status.busy": "2024-12-18T17:14:15.771362Z",
     "iopub.status.idle": "2024-12-18T17:14:15.776968Z",
     "shell.execute_reply": "2024-12-18T17:14:15.776216Z"
    },
    "id": "7b0c992a",
    "papermill": {
     "duration": 0.025354,
     "end_time": "2024-12-18T17:14:15.778667",
     "exception": false,
     "start_time": "2024-12-18T17:14:15.753313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cls_token(tensor, configs=configs):\n",
    "    \"\"\"\n",
    "    Extracts the classification (CLS) token from the input tensor.\n",
    "    \"\"\"\n",
    "    cls_id = configs[\"cls_token_index\"]\n",
    "    return tensor[:, cls_id, :].unsqueeze(1)\n",
    "\n",
    "def flatten_middle(tensor):\n",
    "    \"\"\"\n",
    "    Flattens the middle dimension (sequence length) of the input tensor.\n",
    "    \"\"\"\n",
    "    return tensor.view(tensor.size(0), -1)\n",
    "\n",
    "def freeze_model(model, freeze=True):\n",
    "    \"\"\"\n",
    "    Freeze or unfreeze all parameters of a given model.\n",
    "    \"\"\"\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = not freeze\n",
    "    return model\n",
    "\n",
    "def plot_metric(metric_data, metric_name):\n",
    "    if metric_name is None or metric_name not in metric_data:\n",
    "        raise ValueError(\"No such metric\")\n",
    "    metric_data[metric_name].plot()\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.title(f'Plot of {metric_name}')\n",
    "    plt.show()\n",
    "\n",
    "def calc_percentile_tokens(dataset, tokenizer, field, percentile=configs[\"tok_percentile\"], threshold=1):\n",
    "    \"\"\"\n",
    "    Calculate the token length at a specific percentile for a dataset field.\n",
    "    \"\"\"\n",
    "    tokenized = tokenizer(dataset[field])\n",
    "    \n",
    "    if isinstance(tokenized, dict) and 'input_ids' in tokenized:\n",
    "        token_lengths = [len(x) for x in tokenized['input_ids']]\n",
    "    elif isinstance(tokenized, torch.Tensor):\n",
    "        token_lengths = [t.nonzero().size(0) for t in tokenized]\n",
    "    else:\n",
    "        # Fallback for list of lists\n",
    "        token_lengths = [len(x) for x in tokenized]\n",
    "\n",
    "    if not token_lengths:\n",
    "        return 64 # Default fallback\n",
    "\n",
    "    percentile_length = np.percentile(token_lengths, percentile)\n",
    "    return int(percentile_length) + threshold\n",
    "\n",
    "# Text Encoder Factory (Teacher)\n",
    "def TextEncoder(configs):\n",
    "    new_model = TE.TextTransformer(\n",
    "        context_length=configs['reference_context_length'],\n",
    "        vocab_size=configs[\"reference_vocab_size\"],\n",
    "        width=configs[\"reference_width\"],\n",
    "        layers=configs[\"reference_layers\"],\n",
    "        heads=configs[\"reference_heads\"],\n",
    "        output_dim=configs[\"reference_embedding\"]\n",
    "    )\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2489bf4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T17:14:15.813785Z",
     "iopub.status.busy": "2024-12-18T17:14:15.813542Z",
     "iopub.status.idle": "2024-12-18T17:14:15.820975Z",
     "shell.execute_reply": "2024-12-18T17:14:15.820275Z"
    },
    "id": "2489bf4f",
    "papermill": {
     "duration": 0.026945,
     "end_time": "2024-12-18T17:14:15.822548",
     "exception": false,
     "start_time": "2024-12-18T17:14:15.795603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Swish(nn.Module):\n",
    "    \"\"\"\n",
    "    Swish activation function: x * sigmoid(beta * x)\n",
    "    \"\"\"\n",
    "    def __init__(self, beta=1.0):\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(self.beta * x)\n",
    "\n",
    "class LinearProjection(nn.Module):\n",
    "    \"\"\"\n",
    "    Projection Head: Projects embeddings to the shared space.\n",
    "    - Linear -> Swish -> BatchNorm -> Linear -> Dropout -> LayerNorm (Residual)\n",
    "    \"\"\"\n",
    "    def __init__(self, embedding_dim, projection_dim=configs['project_to'], dropout=configs['dropout']):\n",
    "        super(LinearProjection, self).__init__()\n",
    "        self.projection = nn.Linear(embedding_dim, projection_dim)\n",
    "        self.swish = Swish(beta=1.0)\n",
    "        self.batch_norm = nn.BatchNorm1d(projection_dim)\n",
    "        self.fc = nn.Linear(projection_dim, projection_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(projection_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        projected = self.projection(x)\n",
    "        out = self.swish(projected)\n",
    "        out = self.batch_norm(out)\n",
    "        out = self.fc(out)\n",
    "        out = self.dropout(out)\n",
    "        # Residual connection\n",
    "        return self.layer_norm(out + projected)\n",
    "\n",
    "class CandidateModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Student Model: Wraps the multilingual base model (e.g., LaBSE) and a projection head.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name, unfreeze_layers, trainable=True):\n",
    "        super().__init__()\n",
    "        self.configs = AutoConfig.from_pretrained(model_name)\n",
    "        # We assume the config has a hidden_size\n",
    "        hidden_size = getattr(self.configs, 'hidden_size', 768)\n",
    "        \n",
    "        self.candidateProjection = LinearProjection(embedding_dim=hidden_size, projection_dim=configs['project_to'])\n",
    "        \n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        \n",
    "        # Freezing logic\n",
    "        if trainable:\n",
    "            # Freeze all first\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False\n",
    "            \n",
    "            # Unfreeze the last `unfreeze_layers` layers of the encoder\n",
    "            # Adapting for BERT-like architectures where layers are in model.encoder.layer\n",
    "            if hasattr(self.model, 'encoder') and hasattr(self.model.encoder, 'layer'):\n",
    "                total_layers = len(self.model.encoder.layer)\n",
    "                for i in range(total_layers - unfreeze_layers, total_layers):\n",
    "                    for param in self.model.encoder.layer[i].parameters():\n",
    "                        param.requires_grad = True\n",
    "            elif hasattr(self.model, 'transformer') and hasattr(self.model.transformer, 'layer'):\n",
    "                 # For some other Transformers\n",
    "                 total_layers = len(self.model.transformer.layer)\n",
    "                 for i in range(total_layers - unfreeze_layers, total_layers):\n",
    "                    for param in self.model.transformer.layer[i].parameters():\n",
    "                        param.requires_grad = True\n",
    "                        \n",
    "            # Ensure pooler (if exists) is trainable if we were using it, \n",
    "            # but we use CLS token manually so we check pooler usage? \n",
    "            # Usually we retrain the pooler if we use it. \n",
    "            if hasattr(self.model, 'pooler') and self.model.pooler is not None:\n",
    "                for param in self.model.pooler.parameters():\n",
    "                    param.requires_grad = True\n",
    "        \n",
    "        self.batchNorm = nn.BatchNorm1d(1, hidden_size)\n",
    "        self.targetTokenIdx = configs[\"cls_token_index\"]\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        # Extract CLS token\n",
    "        cls_embed = get_cls_token(output.last_hidden_state) \n",
    "        cls_embed = self.batchNorm(cls_embed)\n",
    "        # Flatten and Project\n",
    "        cls_embed = self.candidateProjection(flatten_middle(cls_embed))\n",
    "        return cls_embed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee90637f",
   "metadata": {
    "id": "ee90637f",
    "papermill": {
     "duration": 0.016248,
     "end_time": "2024-12-18T17:14:15.854449",
     "exception": false,
     "start_time": "2024-12-18T17:14:15.838201",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training Loop\n",
    "Implementation of the Symmetric Contrastive Loss (CLIP Loss) and the training/validation loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83acbdd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T17:14:15.920626Z",
     "iopub.status.busy": "2024-12-18T17:14:15.920377Z",
     "iopub.status.idle": "2024-12-18T17:14:15.927353Z",
     "shell.execute_reply": "2024-12-18T17:14:15.926669Z"
    },
    "id": "83acbdd5",
    "papermill": {
     "duration": 0.02619,
     "end_time": "2024-12-18T17:14:15.929057",
     "exception": false,
     "start_time": "2024-12-18T17:14:15.902867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_loss(batch, reference_model, candidate_model, temperature):\n",
    "    \"\"\"\n",
    "    Compute Symmetric Contrastive Loss:\n",
    "    Loss = (CrossEntropy(sim(A,B)) + CrossEntropy(sim(B,A))) / 2\n",
    "    \"\"\"\n",
    "    candidate_tokenized = batch[\"candidate\"].to(configs[\"device\"])\n",
    "    reference_tokenized = batch[\"reference\"].to(configs[\"device\"])\n",
    "\n",
    "    # Forward pass\n",
    "    reference_embeds = reference_model(reference_tokenized) # Teacher embeddings\n",
    "    candidate_embeds = candidate_model(\n",
    "        input_ids=candidate_tokenized[\"input_ids\"],\n",
    "        attention_mask=candidate_tokenized[\"attention_mask\"]\n",
    "    ) # Student embeddings\n",
    "\n",
    "    # Normalize\n",
    "    reference_embeds = F.normalize(reference_embeds, p=2, dim=-1)\n",
    "    candidate_embeds = F.normalize(candidate_embeds, p=2, dim=-1)\n",
    "\n",
    "    # Similarity matrix\n",
    "    logits = torch.matmul(candidate_embeds, reference_embeds.T) / temperature\n",
    "    \n",
    "    # Targets are diagonal (0, 1, 2, ...) since pairs are aligned in the batch\n",
    "    targets = torch.arange(logits.size(0)).to(configs[\"device\"])\n",
    "    \n",
    "    loss = (\n",
    "        F.cross_entropy(logits, targets) +\n",
    "        F.cross_entropy(logits.T, targets)\n",
    "    ) / 2\n",
    "    \n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    corrects = (preds == targets).sum().item()\n",
    "\n",
    "    return loss, corrects\n",
    "\n",
    "def train_loop(dataloader, models, reference_tokenizer, candidate_tokenizer, optimizer, temperature):\n",
    "    models['candidateModel'].train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_corrects = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    print(\"Training...\")\n",
    "    for (index, pairs) in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        # Tokenize (using get_ds_by_lang functions implicitly or direct keys)\n",
    "        # Note: pairs is a batch dictionary from HuggingFace dataset\n",
    "        \n",
    "        # Tokenize Persian (Student Candidate)\n",
    "        candidate_tokenized = candidate_tokenizer(\n",
    "            pairs[configs['persian']], \n",
    "            padding='max_length', \n",
    "            truncation=True, \n",
    "            return_tensors=\"pt\", \n",
    "            max_length=configs[\"fa_tok_percentile\"]\n",
    "        )\n",
    "        \n",
    "        # Tokenize English (Teacher Reference)\n",
    "        reference_text_tokenized = reference_tokenizer(\n",
    "            pairs[configs['english']]\n",
    "        )\n",
    "\n",
    "        batch = {\n",
    "            \"candidate\" : candidate_tokenized,\n",
    "            \"reference\" : reference_text_tokenized\n",
    "        }\n",
    "\n",
    "        loss, corrects = calc_loss(batch, models['referenceModel'], models['candidateModel'], temperature)\n",
    "        \n",
    "        total_corrects += corrects\n",
    "        total_loss += loss.item() * len(pairs[configs['persian']]) # Sum up loss\n",
    "        total_samples += len(pairs[configs['persian']])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    avg_accuracy = total_corrects / total_samples\n",
    "\n",
    "    print(f\"Train Loss: {avg_loss:.4f} | Train Acc: {avg_accuracy:.4f}\")\n",
    "    return avg_loss, avg_accuracy\n",
    "\n",
    "def val_loop(dataloader, models, reference_tokenizer, candidate_tokenizer, temperature):\n",
    "    models['candidateModel'].eval()\n",
    "\n",
    "    print(\"Validating...\")\n",
    "    total_loss = 0.0\n",
    "    total_corrects = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (index, pairs) in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "            candidate_tokenized = candidate_tokenizer(\n",
    "                pairs[configs['persian']], \n",
    "                padding='max_length', \n",
    "                truncation=True, \n",
    "                return_tensors=\"pt\", \n",
    "                max_length=configs[\"fa_tok_percentile\"]\n",
    "            )\n",
    "            \n",
    "            # Note: OpenCLIP tokenizer usually returns tensor directly or we assume it matches\n",
    "            reference_text_tokenized = reference_tokenizer(\n",
    "                pairs[configs['english']]\n",
    "            )\n",
    "\n",
    "            batch = {\n",
    "                \"candidate\" : candidate_tokenized,\n",
    "                \"reference\" : reference_text_tokenized\n",
    "            }\n",
    "\n",
    "            loss, corrects = calc_loss(batch, models['referenceModel'], models['candidateModel'], temperature)\n",
    "\n",
    "            total_corrects += corrects\n",
    "            total_loss += loss.item() * len(pairs[configs['persian']])\n",
    "            total_samples += len(pairs[configs['persian']])\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    avg_accuracy = total_corrects / total_samples\n",
    "\n",
    "    print(f\"Val Loss: {avg_loss:.4f} | Val Acc: {avg_accuracy:.4f}\")\n",
    "    return avg_loss, avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece3abb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T17:14:15.962709Z",
     "iopub.status.busy": "2024-12-18T17:14:15.962465Z",
     "iopub.status.idle": "2024-12-18T17:14:15.967754Z",
     "shell.execute_reply": "2024-12-18T17:14:15.967000Z"
    },
    "id": "ece3abb5",
    "papermill": {
     "duration": 0.024135,
     "end_time": "2024-12-18T17:14:15.969481",
     "exception": false,
     "start_time": "2024-12-18T17:14:15.945346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocessing Pipeline\n",
    "dataset_train, dataset_val = get_datasets_csv(\n",
    "    \"en\", \"fa\", \n",
    "    configs[\"english\"], configs[\"persian\"], \n",
    "    configs[\"train_path\"], configs[\"val_path\"]\n",
    ")\n",
    "\n",
    "# Apply Normalization\n",
    "dataset_train, dataset_val = apply_preprocess([dataset_train, dataset_val], configs)\n",
    "\n",
    "print(\"Example processed row:\", dataset_train[0])\n",
    "\n",
    "# Dataloaders\n",
    "train_dataloader = DataLoader(dataset_train, batch_size=configs['batch_size'], shuffle=True)\n",
    "val_dataloader = DataLoader(dataset_val, batch_size=configs['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0dd33e",
   "metadata": {
    "id": "4e0dd33e",
    "papermill": {
     "duration": 0.015974,
     "end_time": "2024-12-18T17:14:16.001750",
     "exception": false,
     "start_time": "2024-12-18T17:14:15.985776",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Initialization\n",
    "Initialize tokenizers and models, and calculate dynamic token percentiles for efficient padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e57071",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T17:14:16.065973Z",
     "iopub.status.busy": "2024-12-18T17:14:16.065709Z",
     "iopub.status.idle": "2024-12-18T17:14:16.072545Z",
     "shell.execute_reply": "2024-12-18T17:14:16.071909Z"
    },
    "id": "c8e57071",
    "papermill": {
     "duration": 0.024464,
     "end_time": "2024-12-18T17:14:16.074093",
     "exception": false,
     "start_time": "2024-12-18T17:14:16.049629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Tokenizers\n",
    "reference_tokenizer = open_clip.get_tokenizer(configs[\"reference_checkPoint\"])\n",
    "candidate_tokenizer = AutoTokenizer.from_pretrained(configs[\"candidate_checkpoint\"])\n",
    "\n",
    "# Dynamically update config with student's hidden size\n",
    "candidate_config_obj = AutoConfig.from_pretrained(configs[\"candidate_checkpoint\"])\n",
    "configs[\"candidate_embedding\"] = candidate_config_obj.hidden_size\n",
    "\n",
    "# 2. Calculate Token Percentiles\n",
    "fa_token_len = calc_percentile_tokens(dataset_train, candidate_tokenizer, configs[\"persian\"])\n",
    "en_token_len = calc_percentile_tokens(dataset_train, reference_tokenizer, configs[\"english\"])\n",
    "\n",
    "configs[\"en_tok_percentile\"] = en_token_len\n",
    "configs[\"fa_tok_percentile\"] = fa_token_len\n",
    "\n",
    "print(f\"Calculated Sequence Lengths - FA: {fa_token_len}, EN: {en_token_len}\")\n",
    "\n",
    "# 3. Models\n",
    "reference_model = TextEncoder(configs).to(configs[\"device\"])\n",
    "candidate_model = CandidateModel(\n",
    "    model_name=configs[\"candidate_checkpoint\"], \n",
    "    unfreeze_layers=configs[\"unfreezed_layers\"]\n",
    ").to(configs[\"device\"])\n",
    "\n",
    "# Freeze Teach Model completely\n",
    "reference_model = freeze_model(reference_model, freeze=True)\n",
    "\n",
    "models = {\n",
    "    \"referenceModel\" : reference_model,\n",
    "    \"candidateModel\" : candidate_model\n",
    "}\n",
    "\n",
    "print(f\"Model {configs['candidate_checkpoint']} initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1b4edc",
   "metadata": {
    "id": "5f1b4edc",
    "papermill": {
     "duration": 0.015457,
     "end_time": "2024-12-18T17:14:16.105022",
     "exception": false,
     "start_time": "2024-12-18T17:14:16.089565",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Execution\n",
    "Start the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f0bf97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T17:14:16.137553Z",
     "iopub.status.busy": "2024-12-18T17:14:16.137287Z",
     "iopub.status.idle": "2024-12-18T17:14:16.146093Z",
     "shell.execute_reply": "2024-12-18T17:14:16.145202Z"
    },
    "id": "05f0bf97",
    "papermill": {
     "duration": 0.027335,
     "end_time": "2024-12-18T17:14:16.147775",
     "exception": false,
     "start_time": "2024-12-18T17:14:16.120440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "# Temperature is learned\n",
    "temperature = torch.nn.Parameter(torch.tensor(configs['temperature']).to(configs['device']).float())\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    list(models['candidateModel'].parameters()) + [temperature], \n",
    "    weight_decay=configs[\"weight_decay\"], \n",
    "    lr=configs['lr']\n",
    ")\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    optimizer, 'max', \n",
    "    patience=configs['patience'], \n",
    "    factor=configs['factor']\n",
    ")\n",
    "\n",
    "best_val_acc = float('-inf')\n",
    "metrics = pd.DataFrame(columns=[\"Avg-train-loss\", \"Avg-train-accuracy\", \"Avg-val-loss\", \"Avg-val-accuracy\"])\n",
    "\n",
    "for t in range(configs['epochs']):\n",
    "    print(f\"\\nEpoch {t+1}/{configs['epochs']}\")\n",
    "    train_loss, train_acc = train_loop(\n",
    "        train_dataloader, models, reference_tokenizer, candidate_tokenizer, optimizer, temperature\n",
    "    )\n",
    "    val_loss, val_acc = val_loop(\n",
    "        val_dataloader, models, reference_tokenizer, candidate_tokenizer, temperature\n",
    "    )\n",
    "\n",
    "    metrics.loc[t+1] = [train_loss, train_acc, val_loss, val_acc]\n",
    "    \n",
    "    # Save best\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(models['candidateModel'].state_dict(), configs['save_path'])\n",
    "        print(f\"New best model saved with Acc: {val_acc:.4f}\")\n",
    "\n",
    "    lr_scheduler.step(val_acc)\n",
    "    print(f\"Temperature: {temperature.item():.4f}\")\n",
    "\n",
    "print(f'\\nTraining Complete. Best Validation Accuracy: {best_val_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a0e5e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T17:14:59.958682Z",
     "iopub.status.busy": "2024-12-18T17:14:59.958089Z",
     "iopub.status.idle": "2024-12-18T17:14:59.964595Z",
     "shell.execute_reply": "2024-12-18T17:14:59.963977Z"
    },
    "id": "03a0e5e7",
    "papermill": {
     "duration": 0.025563,
     "end_time": "2024-12-18T17:14:59.966213",
     "exception": false,
     "start_time": "2024-12-18T17:14:59.940650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot Metrics\n",
    "plot_metric(metrics, \"Avg-val-accuracy\")\n",
    "print(metrics.tail(3))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4600270,
     "sourceId": 7845742,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4600399,
     "sourceId": 7845904,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17879.671693,
   "end_time": "2024-12-18T22:11:27.581599",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-18T17:13:27.909906",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
